{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3: Text clustering and topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text clustering groups documents in such a way that documents within a group are more &lsquo;similar&rsquo; to other documents in the cluster than to documents not in the cluster. The exact definition of what &lsquo;similar&rsquo; means in this context varies across applications and clustering algorithms.\n",
    "\n",
    "In this lab you will experiment with both hard and soft clustering techniques. More specifically, in the first part you will be using the $k$-means algorithm, and in the second part you will be using a topic model based on the Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard clustering data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for the hard clustering part of this lab is a collection of product reviews. We have preprocessed the data by tokenization and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open(\"reviews.json.bz2\") as source:\n",
    "    df = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the data frame, you can see that there are three labelled columns: `category` (the product category), `sentiment` (whether the product review was classified as &lsquo;positive&rsquo; or &lsquo;negative&rsquo; towards the product), and `text` (the space-separated text of the review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i bought this album because i loved the title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i was misled and thought i was buying the enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>books</td>\n",
       "      <td>neg</td>\n",
       "      <td>i have introduced many of my ell , high school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>books</td>\n",
       "      <td>pos</td>\n",
       "      <td>anything you purchase in the left behind serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dvd</td>\n",
       "      <td>pos</td>\n",
       "      <td>i loved these movies , and i cant wiat for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category sentiment                                               text\n",
       "0    music       neg  i bought this album because i loved the title ...\n",
       "1    music       neg  i was misled and thought i was buying the enti...\n",
       "2    books       neg  i have introduced many of my ell , high school...\n",
       "3    books       pos  anything you purchase in the left behind serie...\n",
       "4      dvd       pos  i loved these movies , and i cant wiat for the..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to cluster the product review data using a tfâ€“idf vectorizer and a $k$-means clusterer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by doing the vectorization. In connection with vectorization, you should also filter out standard English stop words. While you could use [spaCy](https://spacy.io/) for this task, here it suffices to use the word list implemented in [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to vectorize the data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "corpus = df['text']\n",
    "reviews = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your vectorization by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11914, 46619)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used the English stop word list from scikit-learn, then the resulting vocabulary should have 46,619 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, cluster the vectorized data. Before doing so, you should read the documentation of the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class, which is scikit-learn&rsquo;s implementation of the $k$-means algorithm. As you can see, this class has several parameters that you can tweak. For now, the only parameter that you will have to set is the number of clusters. We recommend that you choose $k=3$.\n",
    "\n",
    "**Tip:** Training $k$-means models will take some time. To speed things up, you can use the `n_init` parameter to control the number of times that the clustering is re-computed with different initial values. The default value for this parameter is 10; here and in the rest of this lab, you may want to set this to a lower value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=5, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Enter code here to cluster the vectorized data\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=5)\n",
    "kmeans.fit(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sanity-check your clustering, create a bar plot with the number of documents per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e10efd35c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Enter code here to produce a bar plot of the cluster size\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.value_counts(kmeans.labels_).plot(kind='bar', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sizes may vary considerable between clusters and among different random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Summarize clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a clustering, you can try to see whether it is meaningful. One useful technique in that context is to generate a **summary** for each cluster by extracting the $n$ highest-weighted terms from the centroid of each cluster. Your next task is to implement this approach.\n",
    "\n",
    "**Hint:** You will need to construct an &lsquo;inverted vocabulary&rsquo; that allows you to map from the index of a term back to the original term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>quality</td>\n",
       "      <td>quot</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>great</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>flash</td>\n",
       "      <td>music</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>use</td>\n",
       "      <td>just</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>digital</td>\n",
       "      <td>cd</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>canon</td>\n",
       "      <td>album</td>\n",
       "      <td>does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>pictures</td>\n",
       "      <td>like</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>lens</td>\n",
       "      <td>movie</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>camera</td>\n",
       "      <td>book</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1         2\n",
       "0     great   good      just\n",
       "1   quality   quot      easy\n",
       "2   battery  great      work\n",
       "3     flash  music      used\n",
       "4       use   just     great\n",
       "5   digital     cd   program\n",
       "6     canon  album      does\n",
       "7  pictures   like  software\n",
       "8      lens  movie       use\n",
       "9    camera   book   product"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_fn(X, n, kmeans):\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    terms_map = {value: key for key, value in vectorizer.vocabulary_.items()}\n",
    "\n",
    "    wordss = list(vectorizer.vocabulary_.keys())\n",
    "    valuess = list(vectorizer.vocabulary_.values())\n",
    "\n",
    "    highest_terms = np.argsort(centroids, axis=1)[:, -n:]\n",
    "\n",
    "    highest_terms\n",
    "    newdata = pd.DataFrame([wordss[valuess.index(idx)] for idx in highest_terms[0,:]])\n",
    "    \n",
    "    for i in range(1,highest_terms.shape[0]):\n",
    "        idxx = highest_terms[i,:]\n",
    "        df = pd.DataFrame({i:[wordss[valuess.index(idx)] for idx in idxx]})\n",
    "        newdata = pd.concat([newdata, df],axis=1)\n",
    "    \n",
    "    return newdata\n",
    "summary_fn(reviews, 10, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>does</td>\n",
       "      <td>band</td>\n",
       "      <td>acting</td>\n",
       "      <td>dvd</td>\n",
       "      <td>written</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>used</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>did</td>\n",
       "      <td>just</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>support</td>\n",
       "      <td>just</td>\n",
       "      <td>good</td>\n",
       "      <td>time</td>\n",
       "      <td>quot</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>easy</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>does</td>\n",
       "      <td>like</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>computer</td>\n",
       "      <td>song</td>\n",
       "      <td>story</td>\n",
       "      <td>use</td>\n",
       "      <td>story</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>version</td>\n",
       "      <td>quot</td>\n",
       "      <td>watch</td>\n",
       "      <td>hair</td>\n",
       "      <td>reading</td>\n",
       "      <td>digital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>use</td>\n",
       "      <td>songs</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>author</td>\n",
       "      <td>canon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>program</td>\n",
       "      <td>music</td>\n",
       "      <td>movies</td>\n",
       "      <td>good</td>\n",
       "      <td>books</td>\n",
       "      <td>pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>software</td>\n",
       "      <td>cd</td>\n",
       "      <td>film</td>\n",
       "      <td>like</td>\n",
       "      <td>read</td>\n",
       "      <td>lens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>product</td>\n",
       "      <td>album</td>\n",
       "      <td>movie</td>\n",
       "      <td>great</td>\n",
       "      <td>book</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1       2      3        4         5\n",
       "0      does   band  acting    dvd  written     great\n",
       "1      used  great   great    did     just   quality\n",
       "2   support   just    good   time     quot   battery\n",
       "3      easy   like    just   does     like     flash\n",
       "4  computer   song   story    use    story       use\n",
       "5   version   quot   watch   hair  reading   digital\n",
       "6       use  songs    like   just   author     canon\n",
       "7   program  music  movies   good    books  pictures\n",
       "8  software     cd    film   like     read      lens\n",
       "9   product  album   movie  great     book    camera"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans6 = KMeans(n_clusters=6, random_state=0, n_init=3)\n",
    "kmeans6.fit(reviews)\n",
    "summary_fn(reviews, 10, kmeans6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1         2\n",
      "0  camera  books  software\n",
      "1  camera  books    health\n",
      "2  camera  books  software\n",
      "3  camera  books    camera\n",
      "4  camera  music    health\n",
      "5  camera  books  software\n",
      "6  camera  music  software\n",
      "7  camera    dvd  software\n",
      "8  camera  music  software\n",
      "9  camera  music  software\n",
      "          0      1    2       3      4       5\n",
      "0  software  music  dvd  health  books  camera\n",
      "1  software  music  dvd  health  books  camera\n",
      "2  software  music  dvd  health  books  camera\n",
      "3  software  music  dvd  health  books  camera\n",
      "4  software  music  dvd  health  books  camera\n",
      "5  software  music  dvd  camera  books  camera\n",
      "6  software  music  dvd  health  books  camera\n",
      "7  software  music  dvd  health  books  camera\n",
      "8  software  music  dvd  health  books  camera\n",
      "9  software  music  dvd  health  books  camera\n"
     ]
    }
   ],
   "source": [
    "def get_n_closest_points(X, n, kmeans):\n",
    "    dist = kmeans.transform(X)\n",
    "    prd = kmeans.predict(X)\n",
    "    data = pd.DataFrame(dist)\n",
    "    \n",
    "    data['id']=range(len(data))    # dist to 0, dist to 1, dist to 2\n",
    "    df['id']=range(len(df))\n",
    "    newdata = pd.merge(data, df, how='left', on='id')\n",
    "    cate = pd.DataFrame(columns = range(dist.shape[1]))\n",
    "    for i in range(dist.shape[1]):      # newdata[pred == i] removes all terms which not belong to the present cluster\n",
    "        cate[i] = newdata[prd == i].sort_values(by=i)[:n]['category'].values\n",
    "    return cate\n",
    "\n",
    "print(get_n_closest_points(reviews, 10, kmeans))\n",
    "print(get_n_closest_points(reviews, 10, kmeans6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = kmeans.transform(reviews)\n",
    "# prd = kmeans.predict(reviews)\n",
    "# data = pd.DataFrame(dist)\n",
    "\n",
    "# data['id']=range(len(data))    # dist to 0, dist to 1, dist to 2\n",
    "# df['id']=range(len(df))\n",
    "\n",
    "# newdata = pd.merge(data, df, how='left', on='id')\n",
    "# k=newdata[kmeans.labels_ == 2].sort_values(by=2)['category']\n",
    "# print(pd.value_counts(k))\n",
    "# print(df['category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have computed the cluster summaries, discuss their quality. Is it clear what the reviews in a given cluster are about? Which clusters are clearest? Which are less clear? Do the cluster summaries contain any unexpected terms? What happens if you re-cluster with, say, $k=6$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Insert your analysis of the clusters here*\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "It seems 3-means algorithm can seperate the text about *camera* from all other categories the clearest, even there are still some missfication for *camera*. The reason might be that text including such words as `lens`, `camera` or `canon` can be defined as *camera* easily. On contrast, other categories are hard to distingish, for instance *music*, *dvd* and *books*, since such words `album`, `quot` or `music` appear frequently. If we set *k=6*, the results seem much better than the one from *k=3*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Tune the k-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major limitation of the $k$-means algorithm is that one has to manually set the value for $k$, the number of clusters. One heuristic that can help you with this is the [Elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)). Your next task is to implement this method to see whether it allows you to find a better value for $k$.\n",
    "\n",
    "To follow the elbow method, you should plot different values of $k$ against the **inertia** (sums of squared distances between documents and closest centroids) of the fitted $k$-means model, and pick the $k$ at the &lsquo;elbow point&rsquo; of the resulting graph. Test cluster sizes between 1 and 9.\n",
    "\n",
    "**Note that this will take a while.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7ef974408>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Enter code here to generate the plot for the elbow method\n",
    "EMS = []\n",
    "for i in range(9):\n",
    "    kms = KMeans(n_clusters=i+1, n_init=3).fit(reviews).inertia_\n",
    "    EMS.append(kms)\n",
    "    \n",
    "pd.Series(EMS).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the diagram, can you see a pronounced &lsquo;elbow point&rsquo;? Discuss your findings in a short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Insert your discussion of the elbow method here*\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "There is no pronounced elbow point in such plot. It seems that Elbow method may not be a good choice for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Compare clusterings using the Rand index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some scenarios, you may have gold-standard class labels available for at least a subset of your documents. In these cases you can compute the **Rand index** of a clustering, and use this measure to compare the quality of different clusterings.\n",
    "\n",
    "To compute the Rand index, we view a clustering as a binary classifier on pairs of documents. The classifier predicts &lsquo;positive&rsquo; if and only if the two documents belong to the same cluster. The (non-normalized) Rand index of the clustering is the accuracy of this classifier relative to a reference in which a document pair belongs to the &lsquo;positive&rsquo; class if and only if the two documents in the pair have the same gold-standard class label.\n",
    "\n",
    "Compare a clustering with $k=3$ clusters to a second clustering with $k=6$ clusters. As your evaluation data, use the first 500 documents from the original data set along with their gold-standard categories (from the `category` column). What do you observe? How do you interpret your observations? What arguments can you find against the Rand index as a measure for comparing clusterings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'true':df['category'],\n",
    "       'pred':kmeans.predict(reviews),\n",
    "       'index':range(df.shape[0])}\n",
    "data4_3 = pd.DataFrame(data).iloc[:500]\n",
    "\n",
    "\n",
    "kmeans6 = KMeans(n_clusters=6,n_init=3).fit(reviews)\n",
    "data = {'true':df['category'],\n",
    "       'pred':kmeans6.predict(reviews),\n",
    "       'index':range(df.shape[0])}\n",
    "data4_6 = pd.DataFrame(data).iloc[:500]\n",
    "\n",
    "def rand_index(data4):\n",
    "    n = data4.shape[0]\n",
    "    tp = 0                 # true positive\n",
    "    for i in range(n):\n",
    "        if(i>0):\n",
    "            for j in range(i):\n",
    "                a = data4.iloc[i]\n",
    "                b = data4.iloc[j]\n",
    "                if (a['true']==b['true'] and a['pred']==b['pred']):\n",
    "                    tp += 1 \n",
    "    return( tp/(n*(n-1)/2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1362565130260521\n",
      "0.10004809619238476\n"
     ]
    }
   ],
   "source": [
    "res4_3 = rand_index(data4_3)\n",
    "res4_6 = rand_index(data4_6)\n",
    "print(res4_3)\n",
    "print(res4_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Insert your discussion of your results here*\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "The rand index of 3-means is higher than the one from 6-means, which means that clustering the original data as 3 classes totally is better than as the number of classes it originally has. One of the reason might be some categories are very hard to distingish, thereby preferring to treat as one class.\n",
    "\n",
    "The size of gold-standard class could be one of the arguments. In addition, false negative, false positive and true negative pairs could also be other 3 arguments that whether we need to consider into the rand index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for the topic modelling part of this lab is the collection of all [State of the Union](https://en.wikipedia.org/wiki/State_of_the_Union) addresses from the years 1975â€“2000. These speeches come as a single text file with one sentence per line. The following code cell prints the first 5 lines from the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr speaker mr vice president members of the 94th congress and distinguished guests\n",
      "twenty six years ago a freshman congressman a young fellow with lots of idealism who was out to change the world stood before sam rayburn in the well of the house and solemnly swore to the same oath that all of you took yesterday an unforgettable experience and i congratulate you all\n",
      "two days later that same freshman stood at the back of this great chamber over there someplace as president truman all charged up by his single handed election victory reported as the constitution requires on the state of the union\n",
      "when the bipartisan applause stopped president truman said i am happy to report to this 81st congress that the state of the union is good our nation is better able than ever before to meet the needs of the american people and to give them their fair chance in the pursuit of happiness it is foremost among the nations of the world in the search for peace\n",
      "today that freshman member from michigan stands where mr truman stood and i must say to you that the state of the union is not good\n",
      "millions of americans are out of work\n"
     ]
    }
   ],
   "source": [
    "with open(\"sotu_1975_2000.txt\") as source:\n",
    "    for i, line in enumerate(source):\n",
    "        print(line.rstrip())\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Train a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task on the topic modelling data is to train an LDA model. For this task you will be using [spaCy](https://spacy.io/) and the [gensim](https://radimrehurek.com/gensim/) topic modelling library.\n",
    "\n",
    "Start by preprocessing the data using spaCy. Given that the data set for this problem is rather small, you do not have to exclude any components from the standard pipeline. Filter out stop words, non-alphabetic tokens, and tokens less than 3 characters in length. Store the documents as a nested list where the first level of nesting corresponds to the sentences and the second level corresponds to the tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the following lines with your own code for preprocessing the documents\n",
    "import spacy\n",
    "with open(\"sotu_1975_2000.txt\") as source:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = [nlp(line) for line in source]\n",
    "    documents = []\n",
    "    for i in range(len(doc)):\n",
    "        lines = []\n",
    "        for token in doc[i]:\n",
    "            if token.is_stop == False and token.lemma_.isalpha() == True and len(token)>=3:\n",
    "                lines.append(token.lemma_)\n",
    "        documents.append(lines)\n",
    "#     documents = [line.split() for line in source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your preprocessing by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reduce oil import million barrel day end year million barrel day end'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(documents[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'reduce oil imports million barrels day end year million barrels day end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the list of documents, skim the section [Pre-process and vectorize the documents](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#pre-process-and-vectorize-the-documents) of the gensim documentation to learn how to create the dictionary and the vectorized corpus representation required by gensim. (Note that you cannot use the standard scikit-learn pipeline in this case.) Then, write code to train an [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) for $k=10$ topics, and using default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to train an LDA model\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "dct = Dictionary(documents)\n",
    "corpus = [dct.doc2bow(text) for text in documents]\n",
    "model = LdaModel(corpus, num_topics=10, id2word=dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a trained model, run the following cell to print the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"america\" + 0.011*\"people\" + 0.011*\"year\" + 0.011*\"new\" + 0.010*\"let\" + 0.009*\"world\" + 0.008*\"work\" + 0.008*\"community\" + 0.008*\"business\" + 0.007*\"nation\"'),\n",
       " (1,\n",
       "  '0.029*\"year\" + 0.016*\"work\" + 0.014*\"child\" + 0.012*\"million\" + 0.012*\"congress\" + 0.012*\"americans\" + 0.010*\"people\" + 0.009*\"budget\" + 0.009*\"new\" + 0.009*\"family\"'),\n",
       " (2,\n",
       "  '0.015*\"new\" + 0.014*\"america\" + 0.012*\"year\" + 0.011*\"nation\" + 0.008*\"congress\" + 0.008*\"people\" + 0.007*\"world\" + 0.007*\"nuclear\" + 0.006*\"tax\" + 0.006*\"work\"'),\n",
       " (3,\n",
       "  '0.008*\"year\" + 0.008*\"policy\" + 0.007*\"congress\" + 0.006*\"time\" + 0.006*\"medium\" + 0.005*\"new\" + 0.005*\"trade\" + 0.005*\"remarkable\" + 0.005*\"american\" + 0.005*\"foreign\"'),\n",
       " (4,\n",
       "  '0.018*\"year\" + 0.015*\"school\" + 0.014*\"work\" + 0.014*\"help\" + 0.013*\"new\" + 0.010*\"child\" + 0.007*\"country\" + 0.007*\"national\" + 0.007*\"family\" + 0.006*\"congress\"'),\n",
       " (5,\n",
       "  '0.015*\"year\" + 0.015*\"america\" + 0.013*\"people\" + 0.010*\"crime\" + 0.008*\"american\" + 0.007*\"world\" + 0.007*\"drug\" + 0.007*\"congress\" + 0.007*\"work\" + 0.006*\"gun\"'),\n",
       " (6,\n",
       "  '0.011*\"work\" + 0.010*\"program\" + 0.009*\"year\" + 0.007*\"support\" + 0.007*\"american\" + 0.006*\"new\" + 0.006*\"economy\" + 0.006*\"state\" + 0.006*\"america\" + 0.005*\"time\"'),\n",
       " (7,\n",
       "  '0.020*\"child\" + 0.019*\"work\" + 0.014*\"parent\" + 0.011*\"support\" + 0.010*\"people\" + 0.010*\"security\" + 0.008*\"help\" + 0.008*\"government\" + 0.007*\"social\" + 0.007*\"long\"'),\n",
       " (8,\n",
       "  '0.013*\"year\" + 0.008*\"right\" + 0.008*\"america\" + 0.007*\"work\" + 0.007*\"people\" + 0.007*\"thank\" + 0.007*\"need\" + 0.007*\"good\" + 0.007*\"community\" + 0.007*\"great\"'),\n",
       " (9,\n",
       "  '0.011*\"people\" + 0.009*\"new\" + 0.007*\"know\" + 0.006*\"ask\" + 0.006*\"act\" + 0.006*\"american\" + 0.005*\"country\" + 0.005*\"challenge\" + 0.005*\"help\" + 0.005*\"world\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the topics. Do they make sense? Can you &lsquo;label&rsquo; each topic with a short description of what it is about? Do the topics contain any unexpected terms? Summarize your discussion in a short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Insert your discussion of the topics here*\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "It makes sense that all the latent topics have *america* or *american*, and some of them are almost readable, such as \"America try to let more american to work in community or business\" and \"America may provide more for the care and security for new children' health\", etc. However, there are also many unreadable topics. For example, we have no idea the mean of *drug* in the second line is medicine or prohibited drugs since there is no clue from other topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Monitoring a topic model for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When learning an LDA model, it is important to make sure that the training algorithm has converged to a stable posterior distribution. One way to do so is to plot, after each training epochs(or &lsquo;pass&rsquo;, in gensim parlance) the log likelihood of the training data under the posterior. Your last task in this lab is to create such a plot and, based on this, to suggest an appropriate number of epochs.\n",
    "\n",
    "To collect information about the posterior likelihood after each pass, we need to enable the logging facilities of gensim. Once this is done, gensim will add various diagnostics to a log file `gensim.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"gensim.log\", format=\"%(asctime)s:%(levelname)s:%(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will parse the generated logfile and return the list of log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_logfile():\n",
    "    matcher = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n",
    "    likelihoods = []\n",
    "    with open(\"gensim.log\") as source:\n",
    "        for line in source:\n",
    "            match = matcher.search(line)\n",
    "            if match:\n",
    "                likelihoods.append(float(match.group(1)))\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to re-train your LDA model for 50&nbsp;passes, retrieve the list of log likelihoods, and create a plot from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7f3acff08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Enter code here to generate the convergence plot\n",
    "model = LdaModel(corpus, num_topics=10, id2word=dct, passes=50)\n",
    "llh = parse_logfile()\n",
    "pd.Series(llh[:50]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"america\" + 0.012*\"year\" + 0.012*\"people\" + 0.011*\"challenge\" + 0.010*\"great\" + 0.009*\"freedom\" + 0.008*\"nation\" + 0.007*\"tonight\" + 0.007*\"house\" + 0.007*\"american\"'),\n",
       " (1,\n",
       "  '0.048*\"year\" + 0.029*\"budget\" + 0.028*\"tax\" + 0.025*\"cut\" + 0.020*\"rate\" + 0.016*\"deficit\" + 0.015*\"high\" + 0.015*\"percent\" + 0.013*\"education\" + 0.013*\"low\"'),\n",
       " (2,\n",
       "  '0.031*\"environment\" + 0.024*\"clean\" + 0.012*\"air\" + 0.012*\"time\" + 0.009*\"housing\" + 0.009*\"fast\" + 0.008*\"waste\" + 0.008*\"labor\" + 0.008*\"environmental\" + 0.008*\"economy\"'),\n",
       " (3,\n",
       "  '0.022*\"crime\" + 0.019*\"government\" + 0.013*\"federal\" + 0.011*\"way\" + 0.011*\"gun\" + 0.010*\"work\" + 0.010*\"people\" + 0.010*\"community\" + 0.009*\"pass\" + 0.009*\"reform\"'),\n",
       " (4,\n",
       "  '0.032*\"world\" + 0.015*\"america\" + 0.014*\"responsibility\" + 0.014*\"welfare\" + 0.013*\"peace\" + 0.012*\"war\" + 0.010*\"freedom\" + 0.010*\"nation\" + 0.009*\"people\" + 0.008*\"work\"'),\n",
       " (5,\n",
       "  '0.033*\"health\" + 0.030*\"care\" + 0.023*\"security\" + 0.018*\"social\" + 0.014*\"year\" + 0.012*\"insurance\" + 0.011*\"medicare\" + 0.011*\"family\" + 0.010*\"work\" + 0.009*\"cost\"'),\n",
       " (6,\n",
       "  '0.026*\"new\" + 0.023*\"america\" + 0.019*\"work\" + 0.019*\"child\" + 0.018*\"community\" + 0.016*\"help\" + 0.015*\"job\" + 0.013*\"people\" + 0.012*\"family\" + 0.011*\"americans\"'),\n",
       " (7,\n",
       "  '0.018*\"child\" + 0.017*\"work\" + 0.017*\"people\" + 0.015*\"school\" + 0.014*\"know\" + 0.013*\"year\" + 0.012*\"congress\" + 0.012*\"let\" + 0.011*\"good\" + 0.008*\"president\"'),\n",
       " (8,\n",
       "  '0.020*\"program\" + 0.014*\"government\" + 0.013*\"congress\" + 0.012*\"federal\" + 0.011*\"energy\" + 0.011*\"year\" + 0.010*\"administration\" + 0.009*\"new\" + 0.009*\"increase\" + 0.008*\"need\"'),\n",
       " (9,\n",
       "  '0.022*\"world\" + 0.017*\"nation\" + 0.013*\"united\" + 0.013*\"trade\" + 0.012*\"peace\" + 0.012*\"soviet\" + 0.011*\"states\" + 0.010*\"country\" + 0.010*\"security\" + 0.009*\"economic\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret your plot? What would be a reasonable choice for the number of passes? Retrain your LDA model with that number and re-inspect the topics it finds. Do you consider the new topics to be &lsquo;better&rsquo; than the ones that you got from the 1-pass model in Problem&nbsp;5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Insert your discussion of these questions here*\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "the plot shows that the log likelihood converges during 50 passes, which means the training algorithm does converge to a stable posterior distribution. It seems we can get a good-enough model when `passes` is more than 9. Compared with the result in Problem 5, the topics are more readable obviously. We can easily find *cut tax*, *gun crime*, *nuclear weapon treat*, etc, not just *america* everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section â€˜General informationâ€™ on the â€˜Labsâ€™ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
